{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from data_prepocessing import  split_data, preprocess_data, normalize_data\n",
    "from utils import save_dataframe_as_csv, set_pandas_display_options, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "dataset_path = '../datasets/raw/titanic.csv'\n",
    "df = load_data(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'passenger_class', 'sex', 'sibling_spouse', 'parent_children', 'fare', 'cabin_number', 'embarked_port'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature_columns =['survived', 'passenger_class',  'sex',\n",
    "       'sibling_spouse', 'parent_children', 'fare', 'cabin_number',\n",
    "       'embarked_port']\n",
    "\n",
    "# selected_feature_columns =['p_class', 'sib_sp','survived']\n",
    "\n",
    "df = df[selected_feature_columns]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "normaliztion_method =  'robust'\n",
    "normalization_columns = ['fare', 'sibling_spouse', 'parent_children']\n",
    "normalization_columns = [ 'sibling_spouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the maximum number of printing columns \n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived             0\n",
       "passenger_class      0\n",
       "sex                  0\n",
       "sibling_spouse       0\n",
       "parent_children      0\n",
       "fare                 0\n",
       "cabin_number       687\n",
       "embarked_port        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing the data that includes removing duplicate and null values\n",
    "print(df.shape)\n",
    "null_counts = df.isnull().sum()\n",
    "null_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibling_spouse</th>\n",
       "      <th>parent_children</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin_number</th>\n",
       "      <th>embarked_port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  passenger_class     sex  sibling_spouse  parent_children     fare cabin_number embarked_port\n",
       "0           0                3    male             1.0                0   7.2500          NaN             S\n",
       "1           1                1  female             1.0                0  71.2833          C85             C\n",
       "2           1                3  female             0.0                0   7.9250          NaN             S\n",
       "3           1                1  female             1.0                0  53.1000         C123             S\n",
       "4           0                3    male             0.0                0   8.0500          NaN             S\n",
       "..        ...              ...     ...             ...              ...      ...          ...           ...\n",
       "886         0                2    male             0.0                0  13.0000          NaN             S\n",
       "887         1                1  female             0.0                0  30.0000          B42             S\n",
       "888         0                3  female             1.0                2  23.4500          NaN             S\n",
       "889         1                1    male             0.0                0  30.0000         C148             C\n",
       "890         0                3    male             0.0                0   7.7500          NaN             Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_data(df, normaliztion_method, normalization_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'passenger_class', 'sex', 'sibling_spouse', 'parent_children', 'fare', 'cabin_number', 'embarked_port'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode 'Sex' column\n",
    "# import pandas as pd\n",
    "# df = pd.get_dummies(df, columns=['sex'], drop_first=False)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['p_class', 'sib_sp'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m df\u001b[38;5;241m.\u001b[39mhead\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# normalize_data(df, normaliztion_method, feature_columns)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#spiliting the data into x_train, y_train, x_test, y_test\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m x_train, x_test, x_val, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/sadeg/source/repos/Titanic-Survival-Prediction/src/data_prepocessing.py:8\u001b[0m, in \u001b[0;36msplit_data\u001b[0;34m(df, feature_column, label_column, test_size, val_size, random_state)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_data\u001b[39m(df, feature_column, label_column, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m,  val_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Split the data into train+val and test\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     x_train_val, x_test, y_train_val, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_column\u001b[49m\u001b[43m]\u001b[49m, df[label_column], \n\u001b[1;32m      9\u001b[0m                                                                 test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Calculate the relative validation size with respect to the train+val set\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     val_size_relative \u001b[38;5;241m=\u001b[39m val_size \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m test_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/titanic/lib/python3.9/site-packages/pandas/core/frame.py:2912\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   2911\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 2912\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   2915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/titanic/lib/python3.9/site-packages/pandas/core/indexing.py:1254\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1254\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_missing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/anaconda3/envs/titanic/lib/python3.9/site-packages/pandas/core/indexing.py:1298\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m   1297\u001b[0m     axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;66;03m# We (temporarily) allow for some missing keys with .loc, except in\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# some cases (e.g. setting) in which \"raise_missing\" will be False\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_missing:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['p_class', 'sib_sp'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#selecting the feature columns \n",
    "feature_columns = ['passenger_class', 'sibling_spouse', 'parent_children', 'fare']\n",
    "feature_columns = ['p_class', 'sib_sp']\n",
    "\n",
    "\n",
    "#selecting the label column\n",
    "label_columns = 'survived'\n",
    "\n",
    "\n",
    "#shuffleing the data before splitting\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head\n",
    "# normalize_data(df, normaliztion_method, feature_columns)\n",
    "\n",
    "#spiliting the data into x_train, y_train, x_test, y_test\n",
    "x_train, x_test, x_val, y_train, y_val, y_test = split_data(df, feature_columns, label_columns, test_size=test_size, val_size=val_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dataframe_as_csv(x_train, \"../datasets/ready/train/x_train.csv\")\n",
    "save_dataframe_as_csv(y_train, \"../datasets/ready/train/y_train.csv\")\n",
    "save_dataframe_as_csv(x_val, \"../datasets/ready/val/x_val.csv\")\n",
    "save_dataframe_as_csv(y_val, \"../datasets/ready/val/y_val.csv\")\n",
    "save_dataframe_as_csv(x_test, \"../datasets/ready/test/x_test.csv\")\n",
    "save_dataframe_as_csv(y_test, \"../datasets/ready/test/y_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
